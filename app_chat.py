# --- 1. æ ¸å¿ƒè¡¥ä¸ (è§£å†³äº‘ç«¯æ•°æ®åº“æŠ¥é”™) ---
import sys
import os

try:
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

# --- 2. é¡µé¢é…ç½® ---
st.set_page_config(page_title="ç”µå•†æ™ºèƒ½å®¢æœ", page_icon="ğŸ›ï¸", layout="wide")
st.title("ğŸ›ï¸ æ­å·ç”µå•†æ™ºèƒ½å®¢æœ (Agentç‰ˆ)")

# åŠ è½½ç¯å¢ƒä¸å¯†é’¥
load_dotenv()
try:
    # ä¼˜å…ˆè¯»äº‘ç«¯ Secrets
    CHAT_KEY = st.secrets["CHAT_API_KEY"]
    EMBED_KEY = st.secrets["EMBED_API_KEY"]
except:
    # æœ¬åœ°è¯» .env
    CHAT_KEY = os.getenv("CHAT_API_KEY")
    EMBED_KEY = os.getenv("EMBED_API_KEY")


# --- 3. åˆå§‹åŒ– Agent (å¸¦ç¼“å­˜) ---
@st.cache_resource
def get_agent():
    print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–å®¢æœ Agent...")

    # A. è¿æ¥ RAG çŸ¥è¯†åº“
    # æ³¨æ„ï¼šç¡®ä¿ chroma_db æ–‡ä»¶å¤¹åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
    if not os.path.exists("./chroma_db"):
        st.error("âŒ æœªæ‰¾åˆ°çŸ¥è¯†åº“æ–‡ä»¶ (chroma_db)ï¼Œè¯·å…ˆåœ¨æœ¬åœ°è¿è¡Œå‘é‡åŒ–è„šæœ¬ã€‚")
        st.stop()

    embedding_model = OpenAIEmbeddings(
        model="embedding-2",
        api_key=EMBED_KEY,
        base_url="https://open.bigmodel.cn/api/paas/v4/",
        check_embedding_ctx_length=False
    )
    vector_db = Chroma(persist_directory="./chroma_db", embedding_function=embedding_model)
    retriever = vector_db.as_retriever(search_kwargs={"k": 3})

    # B. å®šä¹‰å·¥å…·é›†
    @tool
    def lookup_policy(query: str) -> str:
        """æŸ¥é˜…å…¬å¸å†…éƒ¨äº§å“æ‰‹å†Œã€‚å½“ç”¨æˆ·è¯¢é—®äº§å“åŠŸæ•ˆã€é€‚ç”¨è‚¤è´¨ã€æˆåˆ†ã€é€€æ¢è´§æ”¿ç­–æ—¶å¿…é¡»ä½¿ç”¨ã€‚"""
        docs = retriever.invoke(query)
        if not docs: return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        return "\n\n".join([d.page_content for d in docs])

    @tool
    def get_stock(product_name: str) -> str:
        """æŸ¥è¯¢å•†å“åº“å­˜æ•°é‡ã€‚"""
        print(f"Checking stock for {product_name}")
        if "ç¥ä»™æ°´" in product_name: return "åº“å­˜å……è¶³: 88ç“¶"
        if "æ¸…è¹éœ²" in product_name: return "åº“å­˜ç´§å¼ : 5ç“¶"
        return "æš‚æ—¶ç¼ºè´§"

    @tool
    def check_delivery(order_id: str) -> str:
        """æŸ¥è¯¢è®¢å•ç‰©æµçŠ¶æ€ã€‚"""
        return f"è®¢å• {order_id} å·²å‘å‡ºï¼Œå½“å‰ä½ç½®ï¼šæ­å·è§å±±é›†æ•£ä¸­å¿ƒï¼Œé¢„è®¡æ˜æ—¥é€è¾¾ã€‚"

    # C. ç»„è£… LangGraph Agent
    llm = ChatOpenAI(
        model="glm-4.5-air",
        api_key=CHAT_KEY,
        base_url="https://open.bigmodel.cn/api/paas/v4/"
    )

    return create_react_agent(model=llm, tools=[lookup_policy, get_stock, check_delivery])


agent_executor = get_agent()

# --- 4. èŠå¤©ç•Œé¢é€»è¾‘ ---

# åˆå§‹åŒ–å†å²è®°å½•
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ä¾§è¾¹æ ï¼šæ¸…ç©º
with st.sidebar:
    st.markdown("### ğŸ› ï¸ æ§åˆ¶å°")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯è®°å½•"):
        st.session_state["messages"] = []
        st.rerun()

# æ¸²æŸ“å†å²æ¶ˆæ¯
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜ (ä¾‹å¦‚ï¼šç¥ä»™æ°´æ•æ„Ÿè‚Œèƒ½ç”¨å—ï¼Ÿè¿˜æœ‰è´§å—ï¼Ÿ)")

if user_input:
    # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.session_state["messages"].append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # 2. AI æ€è€ƒä¸å›ç­”
    with st.chat_message("assistant"):
        # çŠ¶æ€å®¹å™¨
        with st.status("ğŸ¤– AI æ­£åœ¨å¤šæ­¥æ¨ç†...", expanded=True) as status:
            inputs = {"messages": st.session_state["messages"]}
            final_response = ""

            # æµå¼è·å–æ¯ä¸€æ­¥
            for chunk in agent_executor.stream(inputs, stream_mode="values"):
                latest_msg = chunk["messages"][-1]

                # å·¥å…·è°ƒç”¨æ˜¾ç¤º
                if latest_msg.type == "ai" and latest_msg.tool_calls:
                    tool_name = latest_msg.tool_calls[0]["name"]
                    tool_args = latest_msg.tool_calls[0]["args"]
                    st.write(f"ğŸ”¨ **æ­£åœ¨è°ƒç”¨å·¥å…·**: `{tool_name}`")
                    st.caption(f"å‚æ•°: {tool_args}")

                # å·¥å…·ç»“æœæ˜¾ç¤º
                elif latest_msg.type == "tool":
                    st.write(f"âœ… **å·¥å…·è¿”å›**: {latest_msg.content[:100]}...")

                # æœ€ç»ˆå›å¤
                elif latest_msg.type == "ai":
                    final_response = latest_msg.content

            status.update(label="âœ¨ å›ç­”å®Œæ¯•", state="complete", expanded=False)

        # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
        st.write(final_response)
        st.session_state["messages"].append({"role": "assistant", "content": final_response})
# --- å¿…é¡»æ”¾åœ¨ç¬¬ä¸€è¡Œï¼Œç”¨äºä¿®å¤ Streamlit Cloud çš„æ•°æ®åº“æŠ¥é”™ ---
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# ---------------------------------------------------------

import streamlit as st
# ... (åé¢è·Ÿç€ä½ åŸæ¥çš„ä»£ç )
# --- æ¨¡å— 1: åŸºç¡€è®¾ç½® ---
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

# 1. è®¾ç½®ç½‘é¡µæ ‡é¢˜
st.set_page_config(page_title="æ­å·ç”µå•†æ™ºèƒ½å®¢æœ", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– æ­å·ç”µå•†æ™ºèƒ½å®¢æœ (Agentç‰ˆ)")

# 2. åŠ è½½ç¯å¢ƒ
load_dotenv()
chat_key = os.getenv("CHAT_API_KEY")
embed_key = os.getenv("EMBED_API_KEY")


# 3. å®šä¹‰ç¼“å­˜å‡½æ•° (åªè¿è¡Œä¸€æ¬¡ï¼Œæå¤§æå‡é€Ÿåº¦)
@st.cache_resource
def get_agent():
    print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ– Agent...")

    # --- A. å‡†å¤‡ RAG ---
    embedding_model = OpenAIEmbeddings(
        model="embedding-2",
        api_key=embed_key,
        base_url="https://open.bigmodel.cn/api/paas/v4/",
        check_embedding_ctx_length=False
    )
    vector_db = Chroma(persist_directory="./chroma_db", embedding_function=embedding_model)
    retriever = vector_db.as_retriever(search_kwargs={"k": 3})

    # --- B. å®šä¹‰å·¥å…· ---
    @tool
    def lookup_policy(query: str) -> str:
        """æŸ¥é˜…å…¬å¸å†…éƒ¨çŸ¥è¯†åº“/äº§å“æ‰‹å†Œã€‚å½“ç”¨æˆ·è¯¢é—®äº§å“åŠŸæ•ˆã€æˆåˆ†ã€é€€æ¢è´§æ”¿ç­–æ—¶ä½¿ç”¨ã€‚"""
        docs = retriever.invoke(query)
        if not docs: return "æœªæ‰¾åˆ°ä¿¡æ¯ã€‚"
        return "\n\n".join([d.page_content for d in docs])

    @tool
    def get_stock(product_name: str) -> str:
        """æŸ¥è¯¢å•†å“åº“å­˜ã€‚"""
        if "ç¥ä»™æ°´" in product_name: return "åº“å­˜å……è¶³: 88ç“¶"
        return "æš‚æ—¶ç¼ºè´§"

    @tool
    def check_delivery(order_id: str) -> str:
        """æŸ¥è¯¢ç‰©æµçŠ¶æ€ã€‚"""
        return f"è®¢å• {order_id} å·²å‘å‡ºï¼Œå½“å‰ä½ç½®ï¼šæ­å·è§å±±ã€‚"

    # --- C. ç»„è£… Agent ---
    llm = ChatOpenAI(
        model="glm-4.5-air",
        api_key=chat_key,
        base_url="https://open.bigmodel.cn/api/paas/v4/"
    )

    # åˆ›å»ºå¹¶è¿”å›è¿™ä¸ª Agent
    return create_react_agent(model=llm, tools=[lookup_policy, get_stock, check_delivery])


# è·å– Agent å®ä¾‹
agent_executor = get_agent()

# --- æ¨¡å— 2: èŠå¤©è®°å½•ç®¡ç† ---

# å¦‚æœæŠ½å±‰é‡Œæ²¡æœ‰ messages è¿™ä¸ªæœ¬å­ï¼Œå°±æ”¾ä¸€æœ¬æ–°çš„è¿›å»
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ä¾§è¾¹æ ï¼šæ¸…ç©ºå¯¹è¯æŒ‰é’®
with st.sidebar:
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state["messages"] = []
        st.rerun() # åˆ·æ–°ç½‘é¡µ

# æŠŠæœ¬å­é‡Œçš„å†å²è®°å½•ç”»åœ¨å±å¹•ä¸Š
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- æ¨¡å— 3: å¤„ç†ç”¨æˆ·è¾“å…¥ ---

# å½“ç”¨æˆ·è¾“å…¥äº†å†…å®¹...
user_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜ï¼Œä¾‹å¦‚ï¼šç¥ä»™æ°´æœ‰è´§å—ï¼Ÿ")

if user_input:
    # 1. æ˜¾ç¤ºç”¨æˆ·çš„æ¶ˆæ¯
    with st.chat_message("user"):
        st.write(user_input)
    # è®°åœ¨æœ¬å­ä¸Š
    st.session_state["messages"].append({"role": "user", "content": user_input})

    # 2. AI å¼€å§‹å¹²æ´»
    with st.chat_message("assistant"):
        # åˆ›å»ºä¸€ä¸ªçŠ¶æ€å®¹å™¨ (æ˜¾ç¤º "AI æ­£åœ¨æ€è€ƒ...")
        with st.status("ğŸ¤– AI æ­£åœ¨å¤§è„‘é£æš´...", expanded=True) as status:

            # æ„é€ è¾“å…¥
            inputs = {"messages": st.session_state["messages"]}

            # æµå¼è¿è¡Œ Agent
            final_response = ""
            for chunk in agent_executor.stream(inputs, stream_mode="values"):
                latest_msg = chunk["messages"][-1]

                # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ (Tool Call) -> æ˜¾ç¤ºåœ¨çŠ¶æ€æ¡†é‡Œ
                if latest_msg.type == "ai" and latest_msg.tool_calls:
                    tool_name = latest_msg.tool_calls[0]["name"]
                    tool_args = latest_msg.tool_calls[0]["args"]
                    st.write(f"ğŸ”¨ **æ­£åœ¨è°ƒç”¨å·¥å…·**: `{tool_name}`")
                    st.json(tool_args)  # å±•ç¤ºå‚æ•°

                # å¦‚æœæ˜¯å·¥å…·è¿”å› (Tool Output) -> æ˜¾ç¤ºç»“æœ
                elif latest_msg.type == "tool":
                    st.write(f"âœ… **å·¥å…·è¿”å›ç»“æœ**: {latest_msg.content[:100]}...")  # åªæ˜¾ç¤ºå‰100å­—

                # å¦‚æœæ˜¯æœ€ç»ˆå›å¤
                elif latest_msg.type == "ai" and not latest_msg.tool_calls:
                    final_response = latest_msg.content

            # ä»»åŠ¡å®Œæˆï¼Œæ›´æ–°çŠ¶æ€æ¡†æ ‡é¢˜
            status.update(label="âœ¨ å›ç­”å®Œæ¯•", state="complete", expanded=False)

        # 3. æŠŠæœ€ç»ˆç­”æ¡ˆå†™å‡ºæ¥
        st.write(final_response)
        # è®°åœ¨æœ¬å­ä¸Š
        st.session_state["messages"].append({"role": "assistant", "content": final_response})